---
state: 'published'
title: 'DÃ©couvrir le MCP : Une nouvelle approche pour vos agents IA'
date: 2025-08-14
categories:
  - 'developpement'
tags:
  - 'developpement'
  - 'ia'
  - 'numerique'
heroImage: 'images/Format-Blog-Header-3-scaled.png'
languages:
  - 'fr'
excerpt: 'Avec le MCP, les agents IA se connectent Ã  vos outils et donnÃ©es, agissent en autonomie et transforment votre faÃ§on de dÃ©velopper.'
---

[Cet article est Ã©galement disponible en anglais ! ğŸ‡¬ğŸ‡§](https://noe.tatoud.com/blog/what-is-mcp/)

## Ã‰tat des lieux rapide

Ces derniers mois, l'efficacitÃ© desÂ *LLM*Â nâ€™a cessÃ© de croÃ®tre, bouleversant nos habitudes et notre quotidien de dÃ©veloppeur. De plus en plus sollicitÃ©s pour Ã©crire du code, dÃ©bogguer, concevoir ou nous assister Ã  chaque Ã©tape de notre travail, ces modÃ¨les sont en train de devenir des copilotes incontournables.

> **LLM**Â (Large Language Model, ou grand modÃ¨le de langage) est une intelligence artificielle entraÃ®nÃ©e sur de grandes quantitÃ©s de texte pourÂ **comprendre, gÃ©nÃ©rer et raisonner en langage naturel**.

Le grand public a dÃ©jÃ  commencÃ© Ã  adopter des outils comme ChatGPT (OpenAI), LeChat (Mistral), ou dâ€™autres solutions basÃ©es sur l'IA gÃ©nÃ©rative.

Mais au-delÃ  d'Ã©changes textuels et d'interactions basiques, et si lâ€™on allait plus loin ? Et si lâ€™IA pouvaitÂ **interagir directement et en autonomie avec nos outils**Â ? Modifier du code ? Interroger une base de donnÃ©es ?

Câ€™est prÃ©cisÃ©ment ce que permettent lesÂ **agents IA**.

## Quelle est la diffÃ©rence entre un bot, un assistant IA et un agent IA ?

##### Bot

C'est un programme trÃ¨s simple. Il suit des rÃ¨gles prÃ©-dÃ©finies et donne des rÃ©ponses automatiques. Par exemple, un chatbot sur un site web qui vous propose des rÃ©ponses toutes faites ("Tapez 1 pour parler Ã  un conseiller").  
ğŸ‘‰Â **Il ne comprend pas vraiment, il applique des scripts.**

##### Assistant IAÂ (comme Siri, Alexa ou ChatGPT)

Il est plus avancÃ©. Il comprend ce quâ€™on lui dit, rÃ©pond de maniÃ¨re plus naturelle, et peut effectuer des tÃ¢ches simples (envoyer un message, faire une recherche, etc.).  
ğŸ‘‰ **Il attend qu'on lui parle et fait ce quâ€™on lui demande, mais ne prend pas dâ€™initiatives.**

##### Agent IA

Câ€™est le niveau supÃ©rieur. Il peutÂ **agir seul**, prendre des dÃ©cisionsÂ **sans quâ€™on lui dise quoi faire**, et sâ€™adapter Ã  ce qui se passe autour de lui. Par exemple, un agent IA pourrait surveiller votre boÃ®te mail, repÃ©rer un rendez-vous important, rÃ©server un taxi et vous prÃ©venir â€” sans que vous ayez Ã  le demander.  
**ğŸ‘‰Â Il est autonome, intelligent, et apprend avec le temps.**

Je ne vais pas rentrer dans les dÃ©tails du fonctionnement d'un Agent IA mais vous pouvez lire cet article de Google qui est une bonne entrÃ©e en matiÃ¨re:Â [Google Cloud -Â Qu'est-ce q'un agent IA ?](https://cloud.google.com/discover/what-are-ai-agents?hl=fr)

Jusquâ€™Ã  prÃ©sent, une des contraintes principale dans la crÃ©ation d'un agent Ã©tait qu'il fallait mettre en place des connecteurs uniques, trÃ¨s spÃ©cifiques Ã  chaque source de donnÃ©es et Ã  chaque modÃ¨le. Une approche fastidieuse, peu scalable, et rarement gÃ©nÃ©ralisable.

## MCP: Here comes a new challenger

Câ€™est lÃ  que leÂ **Model Context Protocol (MCP)**Â entre en scÃ¨ne. LancÃ© fin 2024 parÂ **Anthropic**Â (lâ€™entreprise Ã  lâ€™origine de Claude), ce protocole open-source offre aux agents IA une mÃ©thode simple, standardisÃ©e et sÃ©curisÃ©e pour se connecter Ã  des outils, donnÃ©es et services,Â **sans avoir besoin d'intÃ©grations spÃ©cifiques Ã  chaque fois**.

## ThÃ©orie : comment Ã§a fonctionne ?

DerriÃ¨re le Model Context Protocol se cache une idÃ©e simple mais puissante : permettre Ã  une IA deÂ **dÃ©couvrir dynamiquement, interroger et manipuler des outils ou des services**Â sans avoir Ã  Ã©crire une intÃ©gration dÃ©diÃ©e pour chaque cas. Pour y parvenir, MCP dÃ©finit un protocole de communication standardisÃ© entre diffÃ©rents acteurs.

![](images/im1.jpeg)

##### Les acteurs :

**HÃ´tes MCPÂ :** ce sont des applications comme Claude Desktop, des environnements de dÃ©veloppement (IDEs) ou des outils dâ€™IA qui souhaitent accÃ©der Ã  diverses sources de donnÃ©es ou capacitÃ©s via MCP.  
ğŸ‘‰Â **Ils envoient des requÃªtes pour enrichir leur contexte (code, fichiers, docs, etc.) en utilisant le protocole.**

**Clients MCPÂ :** ce sont des composants intermÃ©diaires qui gÃ¨rent une connexion 1:1 avec un serveur MCP.  
ğŸ‘‰Â **Ils traduisent les requÃªtes des hÃ´tes en appels vers un serveur MCP spÃ©cifique, assurant le dialogue entre les deux.**

**Serveurs MCPÂ :** ce sont de petits programmes autonomes qui exposent une fonctionnalitÃ© ou un type de donnÃ©es via le protocole MCP (ex : fichiers locaux, historique Git, base de connaissancesâ€¦).  
ğŸ‘‰Â **Chaque serveur est spÃ©cialisÃ© et peut Ãªtre combinÃ© avec d'autres** **pour enrichir les capacitÃ©s dâ€™un hÃ´te.**

##### Et les assistants IA dans nos IDE ?

Les assistants IA que nous utilisons aujourdâ€™hui dans nos environnements de dÃ©veloppement ont dÃ©jÃ  bien Ã©voluÃ©. Dâ€™abord conÃ§us pour suggÃ©rer du code ou rÃ©pondre Ã  des questions simples, ils deviennent peu Ã  peu deÂ **vÃ©ritables agents intelligents**, capables deÂ **comprendre le contexte**,Â **prendre des dÃ©cisions**, etÂ **agir directement dans nos projets**.

Avec lâ€™arrivÃ©e duÂ **mode agent**Â ces assistants gagnent en autonomie et en flexibilitÃ©. Ils peuvent dÃ©sormais se connecter dynamiquement Ã  des outils externes â€” bases de donnÃ©es, API, fichiers locaux, historique Git, etc... Cela leur permet non seulement de mieux rÃ©pondre Ã  nos requÃªtes, mais aussi dâ€™exÃ©cuter des actions complexes de maniÃ¨re proactive, en sâ€™adaptant Ã  chaque contexte.

Câ€™est une Ã©tape majeure : lâ€™assistant devient acteur, intÃ©grÃ© profondÃ©ment dans notre environnement de travail.

Ajouter des serveurs MCP Ã  ces agents permet deÂ **dÃ©verrouiller des capacitÃ©s sur mesure**Â : accÃ©der Ã  des donnÃ©es locales, interroger des services mÃ©tier, ou manipuler des fichiers spÃ©cifiques. Cela transforme lâ€™agent enÂ **interface unifiÃ©e entre lâ€™IA et nos outils**, sans avoir Ã  coder chaque intÃ©gration Ã  la main.

## Pratique : exemple concret avec TypeScript et `@modelcontextprotocol/sdk`

### Mise en situation

Extrait de donnÃ©es sur les employÃ©s :

```
[
  {
    "nom":Â "Alice Dupont",
    "poste":Â "DÃ©veloppeuse Frontend",
    "anciennete":Â "3 ans",
    "competences":Â "React, TypeScript, UI/UX",
    "statut":Â "CDI"
  },
  {
    "nom":Â "Mehdi Benali",
    "poste":Â "Tech Lead Fullstack",
    "anciennete":Â "5 ans",
    "competences":Â "Java, React, Architecture",
    "statut":Â "CDI"
  },
  {
    "nom":Â "Julie Morel",
    "poste":Â "QA Analyst",
    "anciennete":Â "2 ans",
    "competences":Â "Tests automatisÃ©s, Cypress",Â 
    "statut":Â "CDD"
  },
  {
    "nom":Â "Thomas Leroy",
    "poste":Â "Product Manager",
    "anciennete":Â "4 ans",
    "competences":Â "Agile, Roadmap, Communication",
    "statut":Â "CDI"
  },
  {
    "nom":Â "Claire Nguyen",
    "poste":Â "DÃ©veloppeuse Backend",Â 
    "anciennete":Â "1 an",
    "competences":Â "Node.js, PostgreSQL, Docker",Â 
    "statut":Â "Alternance"
  },
  {
    "nom":Â "Romain Garcia",Â 
    "poste":Â "Designer UI/UX",Â 
    "anciennete":Â "2 ans",
    "competences":Â "Figma, AccessibilitÃ©, Design Sys",Â 
    "statut":Â "Freelance"
  }
]
```

L'objectif ici va Ãªtre de construire un mini serveur MCP afin de rÃ©cupÃ©rer cette liste et de l'utiliser via Cursor.

Initialiser un projet Node 24 avec pnpm :

```
$Â mkdirÂ demo-mcp
$Â cdÂ demo-mcp
$Â pnpmÂ initÂ -y
```

Installer les dÃ©pendances :

```
$Â pnpm addÂ zod @modelcontextprotocol/sdk
```

Nous n'aurons besoin que d'un seul fichier : `main.ts`.

CommenÃ§ons par crÃ©er notre serveur :

```
importÂ {Â McpServerÂ }Â fromÂ "@modelcontextprotocol/sdk/server/mcp.js";

constÂ serverÂ =Â newÂ McpServer({Â 
  name:Â "Gestionnaire d'employÃ©s",Â 
  version:Â "1.0.0",
  description:Â "Un serveur MCP de dÃ©monstration",
});
```

Ok, maintenant ajoutons un outil (tool) Ã  notre serveur.

On doit prÃ©ciser trois choses importantes :

- Le nom de lâ€™outil : `'getEmployees'`

- Une description :Â `"RÃ©cupÃ¨re la liste de tous les employÃ©s en appliquant un filtre si nÃ©cessaire"`. Cela permet au LLM dâ€™avoir plus de contexte pour savoir quand et comment lâ€™utiliser.

- Un schÃ©ma de validation dâ€™entrÃ©e, pour indiquer au LLM quels paramÃ¨tres peuvent Ãªtre utilisÃ©s. On peut utiliser n'importe quelle bibliothÃ¨que de validation suivant leÂ [Standard Schema](https://github.com/standard-schema/standard-schema). Avec `zod`, on peut en plus ajouter des descriptions aux paramÃ¨tres.

- Et bien sÃ»r, le corps de la fonction exÃ©cutÃ©e par lâ€™outil.

Ajoutons tout cela Ã  notre fichier `main.ts` :

```
server.tool(Â 
  "getEmployees",
  "RÃ©cupÃ¨re la liste de tous les employÃ©s en appliquant un filtre si nÃ©cessaire",
  {
    filter:Â z
      .object({Â 
        key:Â z
        .enum(["nom",Â "poste",Â "anciennete",Â "competences",Â "statut"])
        .describe("Les clÃ©s de la table des employÃ©s utilisÃ©es pour filtrer les employÃ©s"),
        value:Â z.string(),
      })
      .optional()
      .describe("Filtrer la liste d'employÃ©s"),
  },
  asyncÂ ({Â filterÂ })Â =>Â {
    constÂ employeesÂ =Â awaitÂ getEmployees({Â 
      where:Â filter?.key,
      value:Â filter?.value,
    });

    returnÂ {
      content:Â [{Â type:Â "text",Â text: JSON.stringify(employees,Â null,Â 2)}],
    };
  }
);
```

Super ! Notre serveur est presque prÃªt, mais il faut maintenant faire en sorte que les clients MCP puissent communiquer avec notre serveur.

Une solution simple est de lire depuis lâ€™entrÃ©e standard et dâ€™Ã©crire sur la sortie standard du processus courant ( `stdio/stdout` ).

Heureusement, la bibliothÃ¨que `@modelcontextprotocol/sdk` fournit une abstraction simple pour cela : `StdioServerTransport`Â .

```
importÂ {Â StdioServerTransportÂ }Â fromÂ "@modelcontextprotocol/sdk/server/stdio.js";

constÂ transportÂ =Â newÂ StdioServerTransport();Â 
awaitÂ server.connect(transport);
```

Et voilÃ , notre serveur est dÃ©sormais prÃªt Ã  Ãªtre utilisÃ© !

Connectons-le Ã  Cursor. Pour cela, il suffit d'ajouter dans notre fichier `.cursor/mcp.json` (Ã  la racine de votre projet par exemple) :

```
{
  "mcpServers":Â {Â 
    "demo-mcp":Â {
      "command":Â "npx",
      "args":Â ["node",Â "/chemin-vers-votre-projet/demo-mcp/main.ts"]
    }
  }
}
```

Maintenant, notre agent IA a accÃ¨s au serveur MCP et aux outils quâ€™il propose.

On peut vÃ©rifier que le serveur est bien connectÃ© dans les paramÃ¨tres de Cursor :

![](images/im2.jpeg)

Maintenant, essayons de lui poser une question, par exemple :  
**"Donne-moi la liste des employÃ©s qui sont en CDI."**

(Ici le modÃ¨le utilisÃ© est `claude-3.5-sonnet`, mais cela n'a pas vraiment dâ€™importance.)

Le LLM va comprendre quâ€™il peut faire appel Ã  lâ€™outil de notre serveur, choisir les bons paramÃ¨tres, rÃ©cupÃ©rer les donnÃ©es, et nous renvoyer une rÃ©ponse formatÃ©e Ã  partir de celles-ci

![](images/im3.jpeg)

## Ã€ quoi s'attendre dans le futur ?

Depuis dÃ©but 2025, lâ€™adoption duÂ **MCP** connaÃ®t une croissance fulgurante. De plus en plus dâ€™acteurs, des startups aux grandes plateformes, contribuent Ã  lâ€™Ã©cosystÃ¨me en publiant desÂ **serveurs MCP**Â capables dâ€™interagir avec toutes sortes de systÃ¨mes : bases de code, bases de donnÃ©es, APIs mÃ©tier, outils internes, fichiers, etc.  
Des noms commeÂ **Microsoft**,Â **Cloudflare**,Â **Open AI**Â ou encore des Ã©diteurs de frameworks et dâ€™IDE sâ€™impliquent activement.

MCP sâ€™impose peu Ã  peu comme leÂ **standard dâ€™interopÃ©rabilitÃ© entre IA et outils mÃ©tiers**. LÃ  oÃ¹ lâ€™on bricolait des connecteurs spÃ©cifiques et rigides, on dispose dÃ©sormais dâ€™un protocoleÂ **modulaire, dÃ©claratif et sÃ©curisÃ©**, conÃ§u pour collaborer naturellement avec des modÃ¨les de langage.

Cela ouvre un nouveau champ de possibilitÃ©s : agents personnalisÃ©s, automatisations intelligentes, assistants capables de naviguer dans une base de code ou d'analyser des logs en contexte, voire mÃªme des actions de haut niveau comme la gestion de dÃ©ploiement ou le contrÃ´le dâ€™environnements.

Le tout, sans dÃ©pendance technologique forte : MCP estÂ **ouvert, extensible et agnostique**, ce qui permet Ã  nâ€™importe quel outil ou service dâ€™exposer ses capacitÃ©s Ã  la volÃ©e.

Alors si vous Ãªtes curieux, testez-le, crÃ©ez vos propres serveurs, exposez vos outils, et partagez vos expÃ©riences avec la communautÃ©.

## Pour aller plus loin

ğŸ‘‰Â [Introduction - Model Context Protocol (Anthropic)](https://modelcontextprotocol.io/introduction)

ğŸ‘‰Â [CrÃ©ez un serveur MCP en 5 Ã©tapes // Un codage efficace (MattÂ Pocock)](https://www.youtube.com/watch?v=FRogt98OF80)

##### Et pour dÃ©couvrir de nouveaux sujets, n'hÃ©sitez pas Ã  consulter nos derniers articles publiÃ©s !

- [Du code au coeur : nos engagements associatifs annuels](https://www.bearstudio.fr/blog/actualites-web-numerique/du-code-au-coeur-nos-engagements-associatifs-annuels)

- [LÃ©a English : Ã‰tude de cas UX](https://www.bearstudio.fr/blog/design-css/lea-english-etude-de-cas)

- [Le bon et le mauvais dÃ©veloppeurs : les soft skills](https://www.bearstudio.fr/blog/developpement/le-bon-et-le-mauvais-chasseur-developpeur-les-soft-skills)

Auteur : NoÃ© Tatoud  
[LinkedIn](https://www.linkedin.com/in/noetatoud/) - [X](https://twitter.com/nowaytatoud) - [Github](https://github.com/ntatoud)
